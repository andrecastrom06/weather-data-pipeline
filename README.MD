# ğŸŒ¦ï¸ Weather Data Pipeline (Olinda/PE)

Pipeline de dados climÃ¡ticos com arquitetura **Medallion (Bronze â†’ Silver â†’ Gold)**, orquestrado com **Apache Airflow** e persistido em **PostgreSQL**.

Este projeto coleta dados atuais de clima da API **OpenWeatherMap** para a cidade de **Olinda/BR**, normaliza o payload JSON e grava os dados tratados em tabela relacional para anÃ¡lise.

---

## âœ… Tecnologias utilizadas

- **Python 3.12+**
- **Apache Airflow 3 (CeleryExecutor)**
- **Docker + Docker Compose**
- **PostgreSQL 16**
- **Redis** (broker do Celery)
- **Pandas**
- **SQLAlchemy**
- **Requests**
- **python-dotenv**
- **Arquitetura Medallion**

---

## ğŸ§± Arquitetura do pipeline

### Bronze (ExtraÃ§Ã£o)
Arquivo: `medallion/bronze.py`

- Consome endpoint `/data/2.5/weather` da OpenWeatherMap.
- Busca clima de `Olinda,BR` em unidade mÃ©trica.
- Salva o JSON bruto em:
  - `data/bronze_olinda_weather.json`

### Silver (TransformaÃ§Ã£o + Carga)
Arquivo: `medallion/silver.py`

- LÃª o JSON da camada bronze.
- Normaliza colunas aninhadas (inclusive `weather`).
- Renomeia campos para padrÃ£o mais analÃ­tico.
- Converte timestamps para timezone `America/Sao_Paulo`.
- Grava no Postgres em:
  - `silver_olinda_weather`

### Gold (AgregaÃ§Ã£o de valores analÃ­ticos)
Arquivo: `medallion/gold.py`

- LÃª os dados tratados da camada Silver (silver_olinda_weather).
- Converte datetime para tipo data.
- Agrupa os dados por:
    `date`
    `sys_country`
- Calcula mÃ©tricas agregadas diÃ¡rias:
    `Temperatura mÃ­nima, mÃ©dia e mÃ¡xima.`
    `Umidade mÃ©dia.`
    `PressÃ£o mÃ©dia.`
    `Velocidade mÃ©dia do vento.`
- Identifica o clima predominante do dia:
    `dominant_weather_main`
    `dominant_weather_description`
- Grava no Postgres em:
    `gold_olinda_weather_daily`

### OrquestraÃ§Ã£o (Airflow)
Arquivo: `dags/weather_dag.py`

- DAG: `weather_pipeline`
- FrequÃªncia: **a cada 5 minutos** (`*/5 * * * *`)
- Ordem das tasks:
  1. `bronze_layer`
  2. `silver_layer`
  3. `gold_layer`

---

## ğŸ“ Estrutura do projeto

```bash
.
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ weather_dag.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ bronze_olinda_weather.json
â”œâ”€â”€ medallion/
â”‚   â”œâ”€â”€ bronze.py
â”‚   â”œâ”€â”€ silver.py
â”‚   â”œâ”€â”€ gold.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ connection.py
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.MD
```

---

## âš™ï¸ ConfiguraÃ§Ã£o de ambiente

Crie o arquivo `config/.env` (o cÃ³digo lÃª variÃ¡veis dessa localizaÃ§Ã£o) com:

```env
# API
API_KEY=sua_chave_openweathermap

# Banco de dados
DB_USER=airflow
DB_PASSWORD=airflow
DB_HOST=postgres
DB_PORT=5432
DB_NAME=airflow
```

> ObservaÃ§Ã£o: para execuÃ§Ã£o local sem Docker, ajuste `DB_HOST` para `localhost` (ou host equivalente).

---

## ğŸš€ Como executar com Docker Compose

### 1) Subir os serviÃ§os

```bash
docker compose up -d
```

### 2) Inicializar/validar containers

```bash
docker compose ps
```

### 3) Acessar interface do Airflow

- URL: `http://localhost:8080`

Ative a DAG `weather_pipeline` e execute manualmente (ou aguarde o agendamento horÃ¡rio).

---

## â–¶ï¸ ExecuÃ§Ã£o manual (sem Airflow)

VocÃª tambÃ©m pode disparar Bronze + Silver diretamente:

```bash
python main.py
```

---

## ğŸ—ƒï¸ Consultando os dados no PostgreSQL

Entrar no container do Postgres:

```bash
docker exec -it etl-postgres-1 psql -U airflow -d airflow
```

Consulta rÃ¡pida:

```sql
SELECT *
FROM silver_olinda_weather
ORDER BY datetime DESC
LIMIT 10;
```

```sql
SELECT *
FROM gold_olinda_weather_daily
ORDER BY date DESC
LIMIT 10;
```

---

## ğŸ” Campos esperados na camada Silver

Alguns campos gerados apÃ³s normalizaÃ§Ã£o:

- `datetime`
- `city`
- `country`
- `temperature`
- `feels_like`
- `humidity`
- `pressure`
- `wind_speed`
- `weather_main`
- `weather_description`
- `sunrise`
- `sunset`

---

## ğŸ§ª DependÃªncias Python

InstalaÃ§Ã£o (execuÃ§Ã£o local):

```bash
pip install -r requirements.txt
```

DependÃªncias principais declaradas no projeto:

- `pandas`
- `requests`
- `python-dotenv`
- `psycopg2-binary`
- `sqlalchemy`
- `pyarrow`

---

## âš ï¸ Pontos de atenÃ§Ã£o

- Sem `API_KEY`, a camada Bronze falha por validaÃ§Ã£o.
- Sem variÃ¡veis de banco (`DB_*`), a conexÃ£o SQLAlchemy nÃ£o Ã© criada.
- A DAG estÃ¡ com `start_date` fixo em 2026 no cÃ³digo; ajuste se quiser retroagir/agendar diferente.

---
